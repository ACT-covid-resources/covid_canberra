---
title: "Location information"
output:
  html_document:
    df_print: paged
---

For this project the location information is one of the defining aspects of the project and future developments. The data is entered into the table as the raw variable called "Exposure.Location". This is the baseline gps information we are able to obtain from the data. There are a several packages that allow for these functions to work.

```{r}
library()
```

## Adding information to the total Exposures released since 2021 delta outbreak

Started on day ...

### Exposure database

[PRIVATE?? unverified as of sept 01]

This database can be extended however the current vertified database include exposure locations from xx date to xx data, Suburb.

Locations are reported on the ACT Health site including 

```{r echo = FALSE, message = FALSE, warning=FALSE}
library(tidyverse)
library(leaflet)

#new data
dat <- read.csv("https://raw.githubusercontent.com/green-striped-gecko/covid_canberra/main/data/last.csv")

########################function to extract summary data#######################




#######################ploting function
#make this aussie captical cities
cities <- read.csv(textConnection("
City,Lat,Long,Pop
Boston,42.3601,-71.0589,645966
Hartford,41.7627,-72.6743,125017
New York City,40.7127,-74.0059,8406000
Philadelphia,39.9500,-75.1667,1553000
Pittsburgh,40.4397,-79.9764,305841
Providence,41.8236,-71.4222,177994
"))

leaflet(cities) %>% addTiles() %>%
  addCircles(lng = ~Long, lat = ~Lat, weight = 1,
    radius = ~sqrt(Pop) * 30, popup = ~City
  )
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

```{r}
library(lubridate)
library(tidyverse)

tab3 <- read_csv("https://raw.githubusercontent.com/green-striped-gecko/covid_canberra/main/data/last.csv")

str(tab3)

# names(tab3)
datyl <-factor(tab3$Contact)
# levels(datyl)

datyl1 <- tab3 %>%
           filter(Status >= "New")

names(tab3)
# colsN <- cols[datyl1]

tab4 <- tab3 %>%
  mutate(colsN = factor(Contact, levels = c("Close", "Casual", "Monitor","Investigation location")),
         Contact = factor(Contact, levels = c("Close", "Casual","Monitor", "Investigation location")))


levels(tab4$colsN) <- c("purple", "red","orange",  "grey50")
levels(tab4$colsN) <- c( "yellow", "red","cyan", "blue")
table(tab4$colsN)

names(tab4)
tab4 %>%
  mutate(conDate = as.Date(lubridate::dmy(Date)),
         locName = as.factor(Exposure.Location))


##loc summaries
tab5 <- tab4 %>%
  mutate(conDate = as.Date(lubridate::dmy(Date)),
         locName = as.factor(Suburb)) 

a <- as.data.frame(table(tab5$locName))

colnames(a) <- c("locName", "contactcount")

# head(a)
# str(a)
# filter(a, contactcount >=1)

plotsumms <- right_join(tab5, a)

print(a)
str(a)

# Aggregate method
# labs <- paste(plotsumms$Exposure.Location, plotsumms$Date,plotsumms$Arrival.Time, plotsumms$Departure.Time, sep="<br/>") 

nrow(tab4)
#> [1] 100
nrow(distinct(plotsumms, Suburb))
b <- distinct(plotsumms, Suburb, .keep_all = TRUE)
# subsTable <- semi_join(tab4, b)


#> [1] 69
# nrow(distinct(df, x, y))
# #> [1] 69
levels(plotsumms$locName)
# distinct(df, x)
plotsumms <- b
plotsumms$Suburb[35] <- "O'Connor" 
plotsumms$locName[35] <- "O'Connor"
# plotsumms$Suburb <- droplevels(plotsumms$Suburb)
# plotsumms$locName <- droplevels(plotsumms$locName)

clean <- plotsumms$Exposure.Location[4] <- "Assembly The People Pub"

# pre-processing
# ensure that all characters in the `Name` column
# are valid UTF-8 encoded
# Thank you to SO for this gem 
# https://stackoverflow.com/questions/17291287/how-to-identify-delete-non-utf-8-characters-in-r
Encoding(x = plotsumms$Exposure.Location) <- "UTF-8"

# replace all non UTF-8 character strings with an empty space
plotsumms$Exposure.Location <-
  iconv( x = plotsumms$Exposure.Location
         , from = "UTF-8"
         , to = "UTF-8"
         , sub = "" )


labs <- paste(plotsumms$Exposure.Location, plotsumms$Date,plotsumms$Arrival.Time, plotsumms$Departure.Time, sep="<br/>") 

leaflet(plotsumms) %>% addTiles() %>%
  addCircleMarkers(lat=plotsumms$lat,
                            lng=plotsumms$lon,
                   weight = 0.2, 
    radius = log(plotsumms$contactcount)*5, 
                            color = plotsumms$colsN,
                            stroke = TRUE,
                            fill = rep("black", length(plotsumms$colsN)),
                            popup = paste0(" COUNT:", plotsumms$contactcount),
                            fillOpacity = 0.8
                            ) %>%
  addCircles(lat=tab4$lat,lng=tab4$lon,
             popup = paste0(plotsumms$Exposure.Location," ", plotsumms$Date))

# %>%
#     group_by(locName) %>%
#       summarise(countPlace = count(Place))
# # %>%
#   group_by(Suburb) %>%
#     summarise(FirstCase = min(conDate),
#               LastCase = max(conDate),
#               caseCount = sum(unique(Place)))

# write.csv(x = plotsumms, "data/outSubs.csv")
```

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.


#### Location x,y information

This needs to account for projection, crs, points, polygons,  SA levels etc...

Locations are reported on the ACT Health site including 

```{r echo = FALSE, message = FALSE, warning=FALSE}
library(tidyverse)
library(leaflet)
cities <- read.csv(textConnection("
City,Lat,Long,Pop
Boston,42.3601,-71.0589,645966
Hartford,41.7627,-72.6743,125017
New York City,40.7127,-74.0059,8406000
Philadelphia,39.9500,-75.1667,1553000
Pittsburgh,40.4397,-79.9764,305841
Providence,41.8236,-71.4222,177994
"))

leaflet(cities) %>% addTiles() %>%
  addCircles(lng = ~Long, lat = ~Lat, weight = 1,
    radius = ~sqrt(Pop) * 30, popup = ~City
  )
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

```{r}
library(lubridate)
library(tidyverse)

tab3 <- read_csv("https://raw.githubusercontent.com/green-striped-gecko/covid_canberra/main/data/last.csv")

str(tab3)

# names(tab3)
datyl <-factor(tab3$Contact)
# levels(datyl)

datyl1 <- tab3 %>%
           filter(Status >= "New")

names(tab3)
# colsN <- cols[datyl1]

tab4 <- tab3 %>%
  mutate(colsN = factor(Contact, levels = c("Close", "Casual", "Monitor","Investigation location")),
         Contact = factor(Contact, levels = c("Close", "Casual","Monitor", "Investigation location")))


levels(tab4$colsN) <- c("purple", "red","orange",  "grey50")
levels(tab4$colsN) <- c( "yellow", "red","cyan", "blue")
table(tab4$colsN)

names(tab4)
tab4 %>%
  mutate(conDate = as.Date(lubridate::dmy(Date)),
         locName = as.factor(Exposure.Location))


##loc summaries
tab5 <- tab4 %>%
  mutate(conDate = as.Date(lubridate::dmy(Date)),
         locName = as.factor(Suburb)) 

a <- as.data.frame(table(tab5$locName))

colnames(a) <- c("locName", "contactcount")

# head(a)
# str(a)
# filter(a, contactcount >=1)

plotsumms <- right_join(tab5, a)

print(a)
str(a)

# Aggregate method
# labs <- paste(plotsumms$Exposure.Location, plotsumms$Date,plotsumms$Arrival.Time, plotsumms$Departure.Time, sep="<br/>") 

nrow(tab4)
#> [1] 100
nrow(distinct(plotsumms, Suburb))
b <- distinct(plotsumms, Suburb, .keep_all = TRUE)
# subsTable <- semi_join(tab4, b)


#> [1] 69
# nrow(distinct(df, x, y))
# #> [1] 69
levels(plotsumms$locName)
# distinct(df, x)
plotsumms <- b
plotsumms$Suburb[35] <- "O'Connor" 
plotsumms$locName[35] <- "O'Connor"
# plotsumms$Suburb <- droplevels(plotsumms$Suburb)
# plotsumms$locName <- droplevels(plotsumms$locName)

clean <- plotsumms$Exposure.Location[4] <- "Assembly The People Pub"

# pre-processing
# ensure that all characters in the `Name` column
# are valid UTF-8 encoded
# Thank you to SO for this gem 
# https://stackoverflow.com/questions/17291287/how-to-identify-delete-non-utf-8-characters-in-r
Encoding(x = plotsumms$Exposure.Location) <- "UTF-8"

# replace all non UTF-8 character strings with an empty space
plotsumms$Exposure.Location <-
  iconv( x = plotsumms$Exposure.Location
         , from = "UTF-8"
         , to = "UTF-8"
         , sub = "" )


labs <- paste(plotsumms$Exposure.Location, plotsumms$Date,plotsumms$Arrival.Time, plotsumms$Departure.Time, sep="<br/>") 

leaflet(plotsumms) %>% addTiles() %>%
  addCircleMarkers(lat=plotsumms$lat,
                            lng=plotsumms$lon,
                   weight = 0.2, 
    radius = log(plotsumms$contactcount)*5, 
                            color = plotsumms$colsN,
                            stroke = TRUE,
                            fill = rep("black", length(plotsumms$colsN)),
                            popup = paste0(" COUNT:", plotsumms$contactcount),
                            fillOpacity = 0.8
                            ) %>%
  addCircles(lat=tab4$lat,lng=tab4$lon,
             popup = paste0(plotsumms$Exposure.Location," ", plotsumms$Date))

# %>%
#     group_by(locName) %>%
#       summarise(countPlace = count(Place))
# # %>%
#   group_by(Suburb) %>%
#     summarise(FirstCase = min(conDate),
#               LastCase = max(conDate),
#               caseCount = sum(unique(Place)))

# write.csv(x = plotsumms, "data/outSubs.csv")
```

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

---
title: "Grouping Canberra suburbs (gammaX[location])"
output:
  html_document:
    df_print: paged
  pdf_document: default
editor_options:
  chunk_output_type: console
---

```{r echo = FALSE,	message = FALSE,	warning = FALSE}
## Global options
# options(max.print="75")
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE,
	cache = FALSE,
	cache.path = "docs/",
	# width=75,
	comment = NA,
	prompt = FALSE,
	tidy = TRUE
)

#and suburbs
# devtools::install_github("wfmackey/absmapsdata")
#stat zones from SA3
library(tidyverse)
library(absmapsdata)
```

Overall we can group locations and other attributes into different spatial areas. For mapping many projects the exact location is not know or is not needed/wanted for a range of obvious reasons. This set of functions takes the location information from each of the datasets and creates a uniform location entry that aligns with the desired spatial scale.

## Existing datasets

```{r}
#census data
#postcode data
# open source map data
```

### Manual postcode grouping


### My grouping 

Here I have created for groups: North Canberra, Central Canberra,.....

# Manual grouping into four general areas.... {.tabset .tabpills}

```{r}
# e.g
subsNorth <- c("Watson", "Hackett")
subsEast <- c("Bruce")
subsCentral <- c("Canberra")
subsSouth <- c("Woden")
outsideACTregion <- c("Jervis Bay", "Wreck Bay", "Hmas Creswell", "Coree", "Mount Stromlo", "Uriarra")
```

## From ABS package

This package allows aspects of this data to be linked with census and other data resources associated with this level of geo-spatial identification.

## LGA_2016 equates to total of ACT

```{r}
library(sf)
library(raster)
library(dplyr)
library(spData)
library(spDataLarge)

dat <- as.data.frame(absmapsdata::lga2016)

seine_simp = st_simplify(absmapsdata::lga2016, dTolerance = 2000) 
plot(seine_simp)


#removes 3 postcoides in NSW jervis area
datArea <- as.data.frame(absmapsdata::lga2016) %>%
          dplyr::select(state_name_2016, lga_name_2016,areasqkm_2016) %>%
            dplyr::filter(!state_name_2016 %in% outsideACTregion)


datArea <- absmapsdata::lga2016 %>%
          # dplyr::select(state_name_2016, lga_name_2016,areasqkm_2016) %>%
            dplyr::filter(!lga_name_2016 %in% outsideACTregion)

datArea1 <- datArea  %>%
          # dplyr::select(state_name_2016, lga_name_2016,areasqkm_2016) %>%
            dplyr::filter(state_name_2016 == 'Australian Capital Territory')

ACTwide <- datArea1[1,]
# plot(ACTwide)

seine_simp = st_simplify(ACTwide, dTolerance = 2000) 
# plot(seine_simp)


# str(dat)
# table(dat$lga_name_2016)

dat2 <- datArea %>%
  dplyr::filter(state_name_2016 == "Australian Capital Territory")

DT::datatable(dat2)

ACTlga <- dat[558, ]

#ACT multipoly
ACTpoly <- ACTlga$geometry[[1]]

ACTpolyGG <- 
ACTpoly %>%
fortify() 

# ACTpolyGG
# %>%
# mutate(aux = c("1"))

# ACTpolyGG$geometry[[1]]
# 
# %>%
# fortify()  %>%
# mutate(aux = c("1"))
# 
# ggplot() +
# geom_polygon(data = ACTpolyGG)
# 
# 
# sf_transform_xy(ACTpoly)
```

```{r echo = FALSE, eval = FALSE}
# attr(,"class")
# [1] "XY"           "MULTIPOLYGON" "sfg" 
# ggspatial::geom_spatial_polygon(ACTlga)
library(plotly)
library(ggplotlyExtra)
library(leaflet)

allfiles <- list.files("../data/allfiles/August/", pattern=c("table_", ".csv"), full.names = TRUE)
#sort patterns

length(allfiles)
allfiles <- allfiles[51]

##sort wrong files


countsperupdate <- function(allfiles){

  allfiledat <- list() #<- list() MUST BE OUTSIDE

    for(i in 1:length(allfiles)) {
      tib <- read_csv(allfiles[i]) %>%
            dplyr::select(Contact, Date, Suburb, Status) %>%
              filter(Status == "New")

    allfiledat[[i]] <- as.data.frame(tib)
  } #end loop

  return(allfiledat, w)

} #end function
# 
# ##setup list of data
allfiledat <- list()
# 
# #run function
allfiledat <- countsperupdate(allfiles = allfiles)

# shape_areas <- shape_df %>%
#   st_as_sf(coords = c("lon", "lat")) %>%
#   group_by(var) %>%
#   summarise(do_union = F) %>%
#   st_cast("POLYGON") %>%
#   st_cast("MULTIPOLYGON") %>%
#   mutate(area = st_area(geometry)) %>% 
#   mutate(var = as.factor(var)) 

##plot the map
m <- leaflet() %>% addTiles()

# head(ACTlga$geometry)
# m %>%
  # addPolygons(ACTlga[[]])
```

## Another abs level

```{r fig.align="c"}
# absmapsdata::postcode2016
#downloaded csv
postcodesACT <- read.csv("../data/au_postcodes.csv") %>%
  dplyr::filter(state_name == "Australian Capital Territory")

# str(postcodesACT$place_name)

postcodesACT1 <- postcodesACT %>%
            dplyr::filter(!place_name %in% outsideACTregion)
# glimpse(postcodesACT)

#standard baseline
# ggmap()

p1 <- ggplot(postcodesACT1) +
  geom_point(aes(y = latitude, x = longitude)) +
  geom_text(aes(y = latitude, x = longitude, label=place_name),hjust=10, vjust=10) + 
  geom_abline(intercept = (max(postcodesACT1$latitude)- min(postcodesACT1$latitude))/2 + min(postcodesACT1$latitude), slope = 0) + 
  geom_vline(xintercept = (max(postcodesACT1$longitude)- min(postcodesACT1$longitude))/2 + min(postcodesACT1$longitude), linetype="dotted", 
                color = "blue", size=0.9, alpha = 0.7) + 
  theme_minimal()
  # geom_line(aes(x = (max(postcodesACT$longitude)- min(postcodesACT$longitude))/2 + min(postcodesACT$longitude), y = 0)
  # geom_label(aes(y = latitude, x = longitude))

mw <- plotly::ggplotly(p1)

mw
            # plotly::add_annotations(p =mw, text = postcodesACT$place_name)

```

## All current locations in cases

```{r eval = FALSE}
    for(i in 1:length(allfiles)) {
      tib <- read_csv(allfiles[i]) %>%
            dplyr::select(Contact, Date, Suburb, Status) %>%
              filter(Status == "New")
      
    allfiledat[[i]] <- as.data.frame(tib)
  } #end loop

postcodesACT1 <- postcodesACT %>%
                  mutate(Suburb = place_name)

singledatpostcode <- allfiledat[[1]] %>%
  left_join(postcodesACT1, by = c('Suburb'))


m1 <- m %>%
  addCircleMarkers(lat=singledatpostcode$latitude,
                   lng=singledatpostcode$longitude) +
  addPolygons(datArea1)

m1
```

### SA3 statistical Areas

```{r}

# sa32016

map <- sa32016 %>%
  filter(gcc_name_2016 == "Australian Capital Territory") %>%   # let's just look Melbourne
  ggplot() +
  geom_sf(aes(geometry = geometry)) +   # use the geometry variable
  geom_point(aes(cent_long, cent_lat))  # use the centroid long (x) and lats (y)

map
```

### SA1 statistical Areas

#### Table

```{r}
DT::datatable(sa12016 %>%
  filter(gcc_name_2016 == "Australian Capital Territory"))
```

#### Plot

```{r}
# sa32016

map <- sa12016 %>%
  filter(gcc_name_2016 == "Australian Capital Territory") %>%   # let's just look Melbourne
  ggplot() +
  geom_sf(aes(geometry = geometry)) +   # use the geometry variable
  geom_point(aes(cent_long, cent_lat))  # use the centroid long (x) and lats (y)

map
```


### SA2 statistical Areas

### Table

```{r}
DT::datatable(sa22016 %>%
  filter(gcc_name_2016 == "Australian Capital Territory"))

```

### Plot

```{r}
# sa32016
library(plotly)
map <- sa22016 %>%
  filter(gcc_name_2016 == "Australian Capital Territory") %>%   # let's just look Melbourne
  ggplot() +   
  ggspatial::annotation_map_tile(zoom = 8) +
  geom_sf(aes(geometry = geometry, fill  = areasqkm_2016)) #   # use the geometry variable
  # geom_point(aes(cent_long, cent_lat))  # use the centroid long (x) and lats (y)
map


# ggplotly(map)
```

###  Total ACT Census data

```{r}
# sa32016 
map <- lga2018 %>%
  filter(state_name_2016 == "Australian Capital Territory") %>%   # let's just look Melbourne
  ggplot() +
  geom_sf(aes(geometry = geometry,  # use the geometry variable
              fill = areasqkm_2018),     # fill by area size
          lwd = 0,                  # remove borders
          show.legend = FALSE) +    # remove legend
  geom_point(aes(cent_long,
                 cent_lat),        # use the centroid long (x) and lats (y)
             colour = "white") +    # make the points white
  theme_void() +                    # clears other plot elements
  coord_sf()

map
```


```{r}
DT::datatable(lga2018 %>%
  filter(state_name_2016 == "Australian Capital Territory"))
```

# plotly


```{r echo = FALSE,	message = FALSE,	warning = FALSE}

## Global options
# options(max.print="75")
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE,
	cache = FALSE,
	cache.path = "docs/",
	# width=75,
	comment = NA,
	prompt = FALSE,
	tidy = TRUE
)
#stat zones from SA3
library(tidyverse)
#and suburbs
# devtools::install_github("wfmackey/absmapsdata")
library(absmapsdata)
```

Overall we can group locations and other attributes into different spatial areas. Here I have created for groups: North Canberra, Central Canberra,.....

Manual grouping into four general areas....

```{r}
# e.g
subsNorth <- c("Watson", "Hackett")
subsEast <- c("Bruce")
subsCentral <- c("Canberra")
subsSouth <- c("Woden")
outsideACTregion <- c("Jervis Bay", "Wreck Bay", "Hmas Creswell", "Coree", "Mount Stromlo", "Uriarra")
```

## From ABS package

This package allows aspects of this data to be linked with census and other data resources associated with this level of geo-spatial identification.

### LGA_2016 equates to total of ACT

```{r}
dat <- as.data.frame(absmapsdata::lga2016)

#removes 3 postcoides in NSW jervis area
datArea <- as.data.frame(absmapsdata::lga2016) %>%
          dplyr::select(state_name_2016, lga_name_2016,areasqkm_2016) %>%
            dplyr::filter(!state_name_2016 %in% outsideACTregion)

# str(dat)
# table(dat$lga_name_2016)

dat2 <- datArea %>%
  dplyr::filter(state_name_2016 == "Australian Capital Territory")

DT::datatable(dat2)

ACTlga <- dat[558, ]

#ACT multipoly
ACTpoly <- ACTlga$geometry[[1]]

ACTpolyGG <- 
ACTpoly %>%
fortify() 

# ACTpolyGG
# %>%
# mutate(aux = c("1"))

# ACTpolyGG$geometry[[1]]
# 
# %>%
# fortify()  %>%
# mutate(aux = c("1"))
# 
# ggplot() +
# geom_polygon(data = ACTpolyGG)
# 
# 
# sf_transform_xy(ACTpoly)
```

```{r echo = FALSE, eval = FALSE}
# attr(,"class")
# [1] "XY"           "MULTIPOLYGON" "sfg" 
# ggspatial::geom_spatial_polygon(ACTlga)
library(plotly)
library(ggplotlyExtra)
library(leaflet)

allfiles <- list.files("../data/allfiles/August/", pattern=c("table_", ".csv"), full.names = TRUE)
#sort patterns

length(allfiles)
allfiles <- allfiles[51]

##sort wrong files


countsperupdate <- function(allfiles){

  allfiledat <- list() #<- list() MUST BE OUTSIDE

    for(i in 1:length(allfiles)) {
      tib <- read_csv(allfiles[i]) %>%
            dplyr::select(Contact, Date, Suburb, Status) %>%
              filter(Status == "New")

    allfiledat[[i]] <- as.data.frame(tib)
  } #end loop

  return(allfiledat, w)

} #end function
# 
# ##setup list of data
allfiledat <- list()
# 
# #run function
allfiledat <- countsperupdate(allfiles = allfiles)

# shape_areas <- shape_df %>%
#   st_as_sf(coords = c("lon", "lat")) %>%
#   group_by(var) %>%
#   summarise(do_union = F) %>%
#   st_cast("POLYGON") %>%
#   st_cast("MULTIPOLYGON") %>%
#   mutate(area = st_area(geometry)) %>% 
#   mutate(var = as.factor(var)) 

##plot the map
m <- leaflet() %>% addTiles()

# head(ACTlga$geometry)
# m %>%
  # addPolygons(ACTlga[[]])
```

### Another abs level

```{r fig.align="c"}
# absmapsdata::postcode2016
#downloaded csv
postcodesACT <- read.csv("../data/au_postcodes.csv") %>%
  dplyr::filter(state_name == "Australian Capital Territory")

# str(postcodesACT$place_name)

outsideACTregion <- c("Jervis Bay", "Wreck Bay", "Hmas Creswell", "Coree", "Mount Stromlo", "Uriarra")

postcodesACT1 <- postcodesACT %>%
                  mutate(Suburb = place_name)
# glimpse(postcodesACT)

#standard baseline
# ggmap()

p1 <- ggplot(postcodesACT1) +
  geom_point(aes(y = latitude, x = longitude)) +
  geom_text(aes(y = latitude, x = longitude, label=place_name),hjust=10, vjust=10) + 
  geom_abline(intercept = (max(postcodesACT1$latitude)- min(postcodesACT1$latitude))/2 + min(postcodesACT1$latitude), slope = 0) + 
  geom_vline(xintercept = (max(postcodesACT1$longitude)- min(postcodesACT1$longitude))/2 + min(postcodesACT1$longitude), linetype="dotted", 
                color = "blue", size=1.5) + 
  theme_minimal()
  # geom_line(aes(x = (max(postcodesACT$longitude)- min(postcodesACT$longitude))/2 + min(postcodesACT$longitude), y = 0)
  # geom_label(aes(y = latitude, x = longitude))

mw <- plotly::ggplotly(p1)

mw
            # plotly::add_annotations(p =mw, text = postcodesACT$place_name)

```

All current locations in cases

```{r eval = TRUE}
library(plotly)
library(maps)
library(leaflet)
# ??addC
##plot the map
m <- leaflet() %>% addTiles()

# absmapsdata::postcode2016
#downloaded csv
# absmapsdata::postcode2016
#downloaded csv
postcodesACT <- read.csv("../data/au_postcodes.csv") %>%
                  mutate(Suburb = place_name) %>%
  dplyr::filter(state_name == "Australian Capital Territory")

# str(postcodesACT$place_name)

outsideACTregion <- c("Jervis Bay", "Wreck Bay", "Hmas Creswell", "Coree", "Mount Stromlo", "Uriarra")

postcodesACT1 <- postcodesACT %>%
            dplyr::filter(!Suburb %in% outsideACTregion)

m1 <- m %>%
  addCircleMarkers(lat=postcodesACT1$latitude,
                   lng=postcodesACT1$longitude)

m1
```



### merged to our cases

```{r}
allfiles <- list.files("../data/allfiles/August/", pattern=c("table_", ".csv"), full.names = TRUE)

countsperupdate <- function(allfiles){
  
  allfiledat <- list() #<- list() MUST BE OUTSIDE

    for(i in 1:length(allfiles)) {
      tib <- read_csv(allfiles[i]) %>%
            dplyr::select(Contact, Date, Suburb, Status) #%>%
              # filter(Status == "New" & Suburb == "Dickson")
      
    allfiledat[[i]] <- as.data.frame(tib)
  } #end loop
  
  return(allfiledat)
  
} #end function

##setup list of data
allfiledat <- list()

#run function
allfiledat <- countsperupdate(allfiles = allfiles)

# ??addCircleMarkers
##how to do this???
# for(i in 1:length(allfiledat)){
  i=1
 singledatpostcode <- allfiledat[[10]] %>%
  left_join(postcodesACT1, by = c('Suburb')) %>%
  remove_missing() 
 i = 2
 singledat <- allfiledat[[20]] %>%
  left_join(postcodesACT1, by = c('Suburb')) %>%
  remove_missing() 
 
 # row_bind
 
# }
##plot the map
m <- leaflet() %>% addTiles()

#only fours match up :)
m1 <- m %>%
  addCircleMarkers(lat=singledatpostcode$latitude,
                   lng=singledatpostcode$longitude)

m1
```



                                                            